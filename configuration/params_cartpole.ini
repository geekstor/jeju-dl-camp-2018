import tensorflow as tf

[ENVIRONMENT]
ENVIRONMENT_TYPE = GYM
GYM_ENV_NAME = CartPole-v0
# TODO: params to WRAP DEEPMIND_ATARI for atari games.

[NETWORK]
# <DEFAULT: Inferred by env.observation_space>, same for action space.
# ACTION_SPECIFICATIONS would define both number of output neurons
# and what to return! Ex. : Pong : [0, 2, 3]
<OPTIONAL, OFTEN REQUIRED: STATE PREPROCESSING MAY BE DONE!>
STATE_DIMENSIONS = [4]
# <REQUIRED (empty array is fine): MAKE NETWORK EXPLICIT>
CONVOLUTIONAL_LAYERS_SPEC = []
# <Again, REQUIRED, unless fully convolutional (unlikely)...?>
DENSE_LAYERS_SPEC = [32, 64, 128]
# <Required: Set to 1 for regular network. (Needs testing.)>
NB_ATOMS = 51
# <REQUIRED> Atari for example takes tf.uint8 to save memory.
STATE_DTYPE = tf.float32

[AGENT]
# <REQUIRED>
AGENT_TYPE = CATEGORICAL

# <REQUIRED> Maximum Num. Transitions to store in the replay memory.
EXPERIENCE_REPLAY_SIZE = 10000

# <DEFAULT: MINIBATCH SIZE>
# Number of Random Actions to take at start (prior to learning).
REPLAY_START_SIZE = 32

# <DEFAULT: 32> PER UPDATE BATCH SIZE
MINIBATCH_SIZE = 32

# <REQUIRED> In Number of **Updates**
COPY_TARGET_FREQ = 1000

# <REQUIRED> Every u_f calls to act(), a minibatch update is performed.
UPDATE_FREQUENCY = 1

# <DEFAULT: 0.99>
DISCOUNT_FACTOR = 0.99

KAPPA = 1.

[ACTION_POLICY]
<REQUIRED>
ACTION_POLICY_TYPE = EPSILON_GREEDY
# EPSILON-GREEDY PARAMETER START
EPSILON_START = 1
# EPSILON GREEDY PARAMETER END
EPSILON_END = 0.01
# In number of actions (since learning).
EPSILON_FINAL_STEP = 3000

[OPTIMIZER]
<REQUIRED>
OPTIMIZER_TYPE = ADAM
# LEARNING RATE FOR ADAM
LEARNING_RATE = 0.001
# EPSILON FOR ADAM
EPSILON_ADAM = 1e-8

[MANAGER]
# Number of Actions to train (agent can do whatever it wants in
# these steps whether act randomly and collect experience or actively
# train on large minibatches).
MAX_TIMESTEPS = 10000
MODELS_FOLDER = "Test-QRDQN\\Models"
TENSORBOARD_FOLDER = "Test-QRDQN\\TensorBoardDir"
EPISODE_RECORD_FREQ = None
# In Number of **Actions**, updates invisible to manager!
MODEL_SAVE_FREQ = 500
MAX_MODELS_TO_KEEP = 10
MIN_MODELS_EVERY_N_HOURS = 2
